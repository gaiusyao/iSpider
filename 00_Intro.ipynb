{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;作为一名 Python “票友”，利用 Python 进行数据分析已成为了一种爱好，也正尝试着通过 Python 数据分析，让自己的工作和生活变得更有趣。\n",
    "\n",
    "&emsp;&emsp;而在学习 Python 数据分析的过程中，发现优质的外部数据至关重要。之前主要从公开数据集（*一些由科研机构、政府或者企业开放的数据集，一般有着较高的质量*）中获取外部数据。这里由衷感谢 [UCI](http://archive.ics.uci.edu/ml/datasets.html)、[kaggle](https://www.kaggle.com/datasets) 等网站，以及 Google 的 [Dataset Search](https://toolbox.google.com/datasetsearch) ，它们整合了大量的优质公开数据集。\n",
    "\n",
    "&emsp;&emsp;但有的时候，为了满足对特定目标进行分析的需求，还需要通过爬虫的方式，爬取互联网上的公开信息。笔者之前只写过一些很简单的爬虫，为了满足学习过程中日益增长的数据需求，决心系统地学习一遍 Python 爬虫，并将爬虫的学习笔记记录到 [iSpider](https://github.com/gaiusyao/iSpider) 这个项目中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;由于 **iSpider**是一个新项目，且用到的第三方库较多，为了不影响到其他项目，先搭建一个虚拟环境。这里选择使用 [Anaconda](https://www.anaconda.com/) 自带的 conda 工具创建虚拟环境：\n",
    "```\n",
    "conda create -n iSpider python=3.7\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;可以通过 `iSpider\\requirements.txt` 文件快速安装相关的第三方库。\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "&emsp;&emsp;生成自己的 `requirements.txt` 文件也非常容易：\n",
    "```\n",
    "pip freeze > requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
